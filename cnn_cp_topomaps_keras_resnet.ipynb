{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import Helper\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22050 images belonging to 3 classes.\n",
      "Found 3150 images belonging to 3 classes.\n",
      "Found 6300 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "h = Helper()\n",
    "\n",
    "train_it, validation_it, test_it = h.construct_data_generator_w_validation(batch_size=10, rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 3)            6147        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(include_top=True, weights=None, input_shape=(224,224,3), classes=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = resnet.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# pred = Dense(3, activation='softmax')(x)\n",
    "# model = Model(inputs=resnet.input, outputs=pred, name='cnn_topomap_classification_model_resnet')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001)\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblog_path = h.logs_directory.format(time())\n",
    "tb_log = TensorBoard(log_dir = tblog_path, profile_batch=0, write_images=True)\n",
    "\n",
    "ch = ModelCheckpoint('models/resnet/cnn_topomap_classification_model_resnet.h5', monitor='val_accuracy', \n",
    "                     mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 1.1647 - accuracy: 0.3730 - val_loss: 1.4555 - val_accuracy: 0.3530\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 461s 209ms/step - loss: 1.0360 - accuracy: 0.4776 - val_loss: 1.4973 - val_accuracy: 0.3702\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 460s 208ms/step - loss: 0.8717 - accuracy: 0.5904 - val_loss: 0.9424 - val_accuracy: 0.5571\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 460s 208ms/step - loss: 0.7556 - accuracy: 0.6589 - val_loss: 0.8726 - val_accuracy: 0.5990\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.6503 - accuracy: 0.7195 - val_loss: 1.2663 - val_accuracy: 0.4924\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.5759 - accuracy: 0.7563 - val_loss: 0.8122 - val_accuracy: 0.6343\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.5054 - accuracy: 0.7880 - val_loss: 0.8174 - val_accuracy: 0.6317\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.4607 - accuracy: 0.8112 - val_loss: 0.7254 - val_accuracy: 0.6987\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.4139 - accuracy: 0.8314 - val_loss: 0.5682 - val_accuracy: 0.7552\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.3841 - accuracy: 0.8444 - val_loss: 0.6258 - val_accuracy: 0.7359\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 461s 209ms/step - loss: 0.3504 - accuracy: 0.8604 - val_loss: 0.5201 - val_accuracy: 0.7876\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.3323 - accuracy: 0.8659 - val_loss: 0.4667 - val_accuracy: 0.8219\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.3075 - accuracy: 0.8799 - val_loss: 0.4380 - val_accuracy: 0.8219\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.2984 - accuracy: 0.8840 - val_loss: 0.3881 - val_accuracy: 0.8527\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 461s 209ms/step - loss: 0.2800 - accuracy: 0.8878 - val_loss: 0.3351 - val_accuracy: 0.8644\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.2613 - accuracy: 0.8971 - val_loss: 0.4097 - val_accuracy: 0.8489\n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.2503 - accuracy: 0.9034 - val_loss: 0.5251 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.2337 - accuracy: 0.9076 - val_loss: 0.8060 - val_accuracy: 0.6886\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.2280 - accuracy: 0.9103 - val_loss: 0.3632 - val_accuracy: 0.8587\n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.2148 - accuracy: 0.9175 - val_loss: 0.4174 - val_accuracy: 0.8371\n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.2093 - accuracy: 0.9174 - val_loss: 0.8349 - val_accuracy: 0.6978\n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1984 - accuracy: 0.9236 - val_loss: 0.4362 - val_accuracy: 0.8390\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1964 - accuracy: 0.9262 - val_loss: 0.3675 - val_accuracy: 0.8778\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1834 - accuracy: 0.9307 - val_loss: 0.3335 - val_accuracy: 0.8686\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.1789 - accuracy: 0.9304 - val_loss: 0.3155 - val_accuracy: 0.8784\n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1692 - accuracy: 0.9341 - val_loss: 0.4908 - val_accuracy: 0.8232\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1687 - accuracy: 0.9356 - val_loss: 0.3593 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1588 - accuracy: 0.9393 - val_loss: 0.3367 - val_accuracy: 0.8721\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.1540 - accuracy: 0.9415 - val_loss: 0.3524 - val_accuracy: 0.8721\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1488 - accuracy: 0.9427 - val_loss: 0.3239 - val_accuracy: 0.8784\n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.1485 - accuracy: 0.9433 - val_loss: 0.2605 - val_accuracy: 0.9067\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1378 - accuracy: 0.9473 - val_loss: 0.2708 - val_accuracy: 0.9044\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1348 - accuracy: 0.9486 - val_loss: 0.2580 - val_accuracy: 0.9057\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1321 - accuracy: 0.9498 - val_loss: 0.6908 - val_accuracy: 0.7638\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.2988 - val_accuracy: 0.8924\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.1250 - accuracy: 0.9529 - val_loss: 0.3391 - val_accuracy: 0.8762\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1195 - accuracy: 0.9550 - val_loss: 0.4910 - val_accuracy: 0.8162\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1194 - accuracy: 0.9551 - val_loss: 0.4088 - val_accuracy: 0.8505\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1182 - accuracy: 0.9550 - val_loss: 0.2867 - val_accuracy: 0.9029\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 456s 207ms/step - loss: 0.1119 - accuracy: 0.9582 - val_loss: 0.3323 - val_accuracy: 0.8835\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 456s 207ms/step - loss: 0.1046 - accuracy: 0.9601 - val_loss: 0.3123 - val_accuracy: 0.8962\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1079 - accuracy: 0.9583 - val_loss: 0.5528 - val_accuracy: 0.7943\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.1053 - accuracy: 0.9595 - val_loss: 0.2916 - val_accuracy: 0.8956\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0967 - accuracy: 0.9640 - val_loss: 0.3851 - val_accuracy: 0.8711\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0961 - accuracy: 0.9633 - val_loss: 0.3586 - val_accuracy: 0.8632\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0939 - accuracy: 0.9652 - val_loss: 0.3714 - val_accuracy: 0.8632\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 460s 208ms/step - loss: 0.0924 - accuracy: 0.9662 - val_loss: 0.2670 - val_accuracy: 0.9127\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0873 - accuracy: 0.9677 - val_loss: 0.2596 - val_accuracy: 0.9111\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0899 - accuracy: 0.9658 - val_loss: 0.2514 - val_accuracy: 0.9175\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 0.3272 - val_accuracy: 0.8876\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0860 - accuracy: 0.9679 - val_loss: 0.5478 - val_accuracy: 0.8114\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0841 - accuracy: 0.9694 - val_loss: 0.2694 - val_accuracy: 0.9051\n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0800 - accuracy: 0.9713 - val_loss: 0.3095 - val_accuracy: 0.8978\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 0.6131 - val_accuracy: 0.7781\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0769 - accuracy: 0.9715 - val_loss: 0.3337 - val_accuracy: 0.8857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0746 - accuracy: 0.9721 - val_loss: 0.2898 - val_accuracy: 0.9019\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0764 - accuracy: 0.9722 - val_loss: 0.3577 - val_accuracy: 0.8832\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0721 - accuracy: 0.9745 - val_loss: 0.4666 - val_accuracy: 0.8565\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0732 - accuracy: 0.9736 - val_loss: 0.2477 - val_accuracy: 0.9229\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0732 - accuracy: 0.9725 - val_loss: 0.2820 - val_accuracy: 0.9146\n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.2852 - val_accuracy: 0.9057\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0665 - accuracy: 0.9756 - val_loss: 0.2724 - val_accuracy: 0.9083\n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 0.3496 - val_accuracy: 0.8765\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0667 - accuracy: 0.9745 - val_loss: 0.2434 - val_accuracy: 0.9263\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0629 - accuracy: 0.9766 - val_loss: 0.8801 - val_accuracy: 0.7384\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.3079 - val_accuracy: 0.9038\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.2841 - val_accuracy: 0.9054\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0610 - accuracy: 0.9772 - val_loss: 1.0989 - val_accuracy: 0.7063\n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 0.2788 - val_accuracy: 0.9086\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0592 - accuracy: 0.9771 - val_loss: 0.3510 - val_accuracy: 0.8848\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0570 - accuracy: 0.9797 - val_loss: 1.1008 - val_accuracy: 0.6911\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0564 - accuracy: 0.9797 - val_loss: 0.2729 - val_accuracy: 0.9181\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.0537 - accuracy: 0.9806 - val_loss: 0.2557 - val_accuracy: 0.9286\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0552 - accuracy: 0.9796 - val_loss: 0.2885 - val_accuracy: 0.9187\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.3112 - val_accuracy: 0.9086\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0512 - accuracy: 0.9811 - val_loss: 0.4480 - val_accuracy: 0.8556\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.7436 - val_accuracy: 0.7787\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0523 - accuracy: 0.9812 - val_loss: 0.2708 - val_accuracy: 0.9105\n",
      "Epoch 79/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.3729 - val_accuracy: 0.8730\n",
      "Epoch 80/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.6073 - val_accuracy: 0.7984\n",
      "Epoch 81/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 0.3228 - val_accuracy: 0.8971\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.3106 - val_accuracy: 0.8978\n",
      "Epoch 83/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.2420 - val_accuracy: 0.9314\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.5623 - val_accuracy: 0.8273\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.4406 - val_accuracy: 0.8775\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.3769 - val_accuracy: 0.8768\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 460s 209ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.8174 - val_accuracy: 0.7711\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 456s 207ms/step - loss: 0.0463 - accuracy: 0.9826 - val_loss: 0.5451 - val_accuracy: 0.8390\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0451 - accuracy: 0.9837 - val_loss: 0.2999 - val_accuracy: 0.8990\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 457s 207ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.2831 - val_accuracy: 0.9181\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.4017 - val_accuracy: 0.8781\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0438 - accuracy: 0.9842 - val_loss: 0.3067 - val_accuracy: 0.9044\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.4432 - val_accuracy: 0.8600\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0407 - accuracy: 0.9862 - val_loss: 0.2523 - val_accuracy: 0.9241\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.2764 - val_accuracy: 0.9206\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0395 - accuracy: 0.9855 - val_loss: 0.2385 - val_accuracy: 0.9289\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 0.2530 - val_accuracy: 0.9219\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 0.3294 - val_accuracy: 0.9041\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.6107 - val_accuracy: 0.8190\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 458s 208ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.7672 - val_accuracy: 0.7479\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(train_it, epochs=100, callbacks=[ch, tb_log], validation_data=validation_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = model.evaluate_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved, path: models/cnn_topomap_classification_model_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "h.save(model, r, evaluate, y_prob, 'cnn_topomap_classification_model_resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ch = h.load('models/resnet/cnn_topomap_classification_model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ch = model_ch.evaluate_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24716005615818365, 0.9285714]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8cc692b5035b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss curve for cnn_topomap_classification_model_resnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title('loss curve for cnn_topomap_classification_model_resnet')\n",
    "\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('results/loss curve for cnn_topomap_classification_model_resnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title('accuracy curve for cnn_topomap_classification_model_resnet')\n",
    "\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('results/accuracy curve for cnn_topomap_classification_model_resnet.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
